{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45fc9086-93aa-4645-8ba2-380c3acbbed9",
   "metadata": {},
   "source": [
    "# A simple two-agent A2A RAG Application\n",
    "\n",
    "This notebook presents a simple scenario where an agent uses the A2A protocol to query another agent for information as it answers a RAG query. We show how to initialize an agent in Llama Stack and grant it access to communicating with another, external agent.\n",
    "\n",
    "This demo is largely based on the single-agent RAG demo. It can be found in [Level4_RAG_agent.ipynb](../../rag_agentic/notebooks/Level4_RAG_agent.ipynb).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook covers the following steps:\n",
    "\n",
    "1. Setting up a Llama Stack agent capable of retrieving content from vector DB via the builtin RAG tool.\n",
    "2. Serving the agent over an A2A server.\n",
    "3. Initializing another Llama Stack capable of communicating with the RAG agent.\n",
    "4. Launching the second agent and using it to answer user queries about the documents.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting, ensure you have the following:\n",
    "- `python_requires >= 3.11`\n",
    "\n",
    "- Followed the instructions in the [Setup Guide](../../rag_agentic/notebooks/Level0_getting_started_with_Llama_Stack.ipynb) notebook. \n",
    "\n",
    "- Llama Stack server should be using milvus as its vector DB provider.\n",
    "\n",
    "## Additional environment variables\n",
    "This demo requires the following environment variables in addition to those defined in the [Setup Guide](../../rag_agentic/notebooks//Level0_getting_started_with_Llama_Stack.ipynb):\n",
    "- `RAG_AGENT_LOCAL_PORT`: the port over which we will serve the exported A2A agent with RAG capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e11c00-19f0-4265-b4c4-73ec3a1936a7",
   "metadata": {},
   "source": [
    "## 1. Setting Up this Notebook\n",
    "To provide A2A communication capabilities, we will use the [sample implementation by Google](https://github.com/google/A2A/tree/main/samples/python). Please make sure that the content of the referenced directory is available on your Python path. This can be done, for example, by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e50535c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'a2a-samples' already exists and is not an empty directory.\n",
      "Requirement already satisfied: annotated-types==0.7.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: anyio==4.9.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: appnope==0.1.4 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 3)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==3.0.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: asyncclick==8.1.8 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 5)) (8.1.8.0)\n",
      "Requirement already satisfied: certifi==2025.1.31 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 6)) (2025.1.31)\n",
      "Requirement already satisfied: cffi==1.17.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.4.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 8)) (3.4.2)\n",
      "Requirement already satisfied: click==8.1.8 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 9)) (8.1.8)\n",
      "Requirement already satisfied: comm==0.2.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 10)) (0.2.2)\n",
      "Requirement already satisfied: cryptography==45.0.3 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 11)) (45.0.3)\n",
      "Requirement already satisfied: debugpy==1.8.14 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 12)) (1.8.14)\n",
      "Requirement already satisfied: decorator==5.2.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 13)) (5.2.1)\n",
      "Requirement already satisfied: distro==1.9.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 14)) (1.9.0)\n",
      "Requirement already satisfied: dotenv==0.9.9 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 15)) (0.9.9)\n",
      "Requirement already satisfied: executing==2.2.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 16)) (2.2.0)\n",
      "Requirement already satisfied: fire==0.7.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 17)) (0.7.0)\n",
      "Requirement already satisfied: h11==0.16.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 18)) (0.16.0)\n",
      "Requirement already satisfied: httpcore==1.0.9 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 19)) (1.0.9)\n",
      "Requirement already satisfied: httpx==0.28.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 20)) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 21)) (0.4.0)\n",
      "Requirement already satisfied: idna==3.10 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 22)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 23)) (6.29.5)\n",
      "Requirement already satisfied: ipython==9.3.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 24)) (9.3.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 25)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 26)) (0.19.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 27)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.8.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 28)) (5.8.1)\n",
      "Requirement already satisfied: jwcrypto==1.5.6 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 29)) (1.5.6)\n",
      "Requirement already satisfied: llama_stack_client==0.2.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 30)) (0.2.2)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 31)) (3.0.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 32)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 33)) (0.1.2)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 34)) (1.6.0)\n",
      "Requirement already satisfied: numpy==2.2.5 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 35)) (2.2.5)\n",
      "Requirement already satisfied: packaging==25.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 36)) (25.0)\n",
      "Requirement already satisfied: pandas==2.2.3 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 37)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 38)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 39)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.3.8 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 40)) (4.3.8)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.51 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 41)) (3.0.51)\n",
      "Requirement already satisfied: psutil==7.0.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 42)) (7.0.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 43)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 44)) (0.2.3)\n",
      "Requirement already satisfied: pyaml==25.1.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 45)) (25.1.0)\n",
      "Requirement already satisfied: pycparser==2.22 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 46)) (2.22)\n",
      "Requirement already satisfied: pydantic==2.11.3 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 47)) (2.11.3)\n",
      "Requirement already satisfied: pydantic_core==2.33.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 48)) (2.33.1)\n",
      "Requirement already satisfied: Pygments==2.19.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 49)) (2.19.1)\n",
      "Requirement already satisfied: PyJWT==2.10.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 50)) (2.10.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 51)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv==1.1.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 52)) (1.1.0)\n",
      "Requirement already satisfied: pytz==2025.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 53)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 54)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.4.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 55)) (26.4.0)\n",
      "Requirement already satisfied: requests==2.32.3 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 56)) (2.32.3)\n",
      "Requirement already satisfied: rich==14.0.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 57)) (14.0.0)\n",
      "Requirement already satisfied: six==1.17.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 58)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 59)) (1.3.1)\n",
      "Requirement already satisfied: sse-starlette==2.2.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 60)) (2.2.1)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 61)) (0.6.3)\n",
      "Requirement already satisfied: starlette==0.46.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 62)) (0.46.2)\n",
      "Requirement already satisfied: termcolor==3.0.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 63)) (3.0.1)\n",
      "Requirement already satisfied: tornado==6.5.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 64)) (6.5.1)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 65)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 66)) (5.14.3)\n",
      "Requirement already satisfied: typing-inspection==0.4.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 67)) (0.4.0)\n",
      "Requirement already satisfied: typing_extensions==4.13.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 68)) (4.13.2)\n",
      "Requirement already satisfied: tzdata==2025.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 69)) (2025.2)\n",
      "Requirement already satisfied: urllib3==2.4.0 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 70)) (2.4.0)\n",
      "Requirement already satisfied: uvicorn==0.34.2 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 71)) (0.34.2)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /Users/kcogan/Documents/llama-stack-on-ocp/venv/lib/python3.11/site-packages (from -r ../requirements.txt (line 72)) (0.2.13)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/google-a2a/a2a-samples.git\n",
    "! pip install -r \"../requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1892cd-a569-40d1-81a0-144e3597ab43",
   "metadata": {},
   "source": [
    "Now, we will add the paths to the A2A library and our own tools to `sys.path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92301f97-17f4-4f48-a3da-a5288b8b02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# the path of the A2A library\n",
    "sys.path.append('./a2a-samples/samples/python')\n",
    "# the path to our own utils\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c488f7d-7dca-4169-9602-a1435290c57d",
   "metadata": {},
   "source": [
    "We will now proceed with the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839cf607-0301-41dc-ab13-d57b9ac20bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.server import A2AServer\n",
    "from common.types import AgentCard, AgentSkill, AgentCapabilities\n",
    "from a2a_llama_stack.A2ATool import A2ATool\n",
    "from a2a_llama_stack.task_manager import AgentTaskManager\n",
    "\n",
    "# for asynchronously serving the A2A agent\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d33a4-24c9-49fa-a068-70f6ae496e9f",
   "metadata": {},
   "source": [
    "Next, we will initialize our environment as described in detail in our [\"Getting Started\" notebook](demos/rag_agentic/notebooks/Level0_getting_started_with_Llama_Stack.ipynb). Please refer to it for additional explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b87b139-bd18-47b2-889a-1b8ed3018655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server\n",
      "Inference Parameters:\n",
      "\tModel: llama3.1:8b-instruct-fp16\n",
      "\tSampling Parameters: {'strategy': {'type': 'greedy'}, 'max_tokens': 512}\n",
      "\tstream: False\n"
     ]
    }
   ],
   "source": [
    "# for accessing the environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# for communication with Llama Stack\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "# agent- and RAG-related imports\n",
    "import uuid\n",
    "from llama_stack_client import Agent, RAGDocument\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "\n",
    "# pretty print of the results returned from the model/agent - import from the agentic_rag demo subdirectory\n",
    "import sys\n",
    "sys.path.append('../../rag_agentic')  \n",
    "from src.utils import step_printer\n",
    "from termcolor import cprint\n",
    "\n",
    "\n",
    "base_url = os.getenv(\"REMOTE_BASE_URL\")\n",
    "\n",
    "\n",
    "# Tavily search API key is required for some of our demos and must be provided to the client upon initialization.\n",
    "# We will cover it in the agentic demos that use the respective tool. Please ignore this parameter for all other demos.\n",
    "tavily_search_api_key = os.getenv(\"TAVILY_SEARCH_API_KEY\")\n",
    "if tavily_search_api_key is None:\n",
    "    provider_data = None\n",
    "else:\n",
    "    provider_data = {\"tavily_search_api_key\": tavily_search_api_key}\n",
    "\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url,\n",
    "    provider_data=provider_data\n",
    ")\n",
    "    \n",
    "print(f\"Connected to Llama Stack server\")\n",
    "\n",
    "# model_id for the model you wish to use that is configured with the Llama Stack server\n",
    "model_id = os.getenv(\"INFERENCE_MODEL_ID\")\n",
    "\n",
    "temperature = float(os.getenv(\"TEMPERATURE\", 0.0))\n",
    "if temperature > 0.0:\n",
    "    top_p = float(os.getenv(\"TOP_P\", 0.95))\n",
    "    strategy = {\"type\": \"top_p\", \"temperature\": temperature, \"top_p\": top_p}\n",
    "else:\n",
    "    strategy = {\"type\": \"greedy\"}\n",
    "\n",
    "max_tokens = int(os.getenv(\"MAX_TOKENS\", 4096))\n",
    "\n",
    "# sampling_params will later be used to pass the parameters to Llama Stack Agents/Inference APIs\n",
    "sampling_params = {\n",
    "    \"strategy\": strategy,\n",
    "    \"max_tokens\": max_tokens,\n",
    "}\n",
    "\n",
    "stream_env = os.getenv(\"STREAM\", \"False\")\n",
    "# the Boolean 'stream' parameter will later be passed to Llama Stack Agents/Inference APIs\n",
    "# any value non equal to 'False' will be considered as 'True'\n",
    "stream = (stream_env != \"False\")\n",
    "\n",
    "print(f\"Inference Parameters:\\n\\tModel: {model_id}\\n\\tSampling Parameters: {sampling_params}\\n\\tstream: {stream}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b1662-2d8b-429f-b51a-de58081a9667",
   "metadata": {},
   "source": [
    "## 2. Setting Up and Serving a RAG A2A Agent\n",
    "We will now initialize an agent connected to a vector DB and capable of serving requests related to the information contained in the indexed documents.\n",
    "\n",
    "Our first steps will be identical to those demonstrated in [Level4_RAG_agent.ipynb](demos/rag_agentic/notebooks/Level4_RAG_agent.ipynb):\n",
    "- Initialize a new document collection in the target vector DB. All parameters related to the vector DB, such as the embedding model and dimension, must be specified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8ee65a-5925-44ed-a81b-f0df2c52465e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorDBRegisterResponse(embedding_dimension=384, embedding_model='all-MiniLM-L6-v2', identifier='test_vector_db_8f5fc8f5-2e61-4c37-baa2-ae497aca3990', provider_id='faiss', provider_resource_id='test_vector_db_8f5fc8f5-2e61-4c37-baa2-ae497aca3990', type='vector_db', access_attributes=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db_id = f\"test_vector_db_{uuid.uuid4()}\"\n",
    "\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    embedding_model=os.getenv(\"VDB_EMBEDDING\"),\n",
    "    embedding_dimension=int(os.getenv(\"VDB_EMBEDDING_DIMENSION\", 384)),\n",
    "    provider_id=os.getenv(\"VDB_PROVIDER\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722b6e6-3ed1-4af6-aa1c-3d7c973baf44",
   "metadata": {},
   "source": [
    "- Provide a list of document URLs to the RAG tool. Llama Stack will handle the fetching, conversion and chunking of the documents' content automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e86b69-7b8e-4418-976c-2a694a99a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    (\"https://www.openshift.guide/openshift-guide-screen.pdf\", \"application/pdf\"),\n",
    "]\n",
    "documents = [\n",
    "    RAGDocument(\n",
    "        document_id=f\"num-{i}\",\n",
    "        content=url,\n",
    "        mime_type=url_type,\n",
    "        metadata={},\n",
    "    )\n",
    "    for i, (url, url_type) in enumerate(urls)\n",
    "]\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=int(os.getenv(\"VECTOR_DB_CHUNK_SIZE\", 512)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f72d4-ec1c-4391-bf01-8ac3348aa328",
   "metadata": {},
   "source": [
    "- Initialize a Llama Stack agent with a list of tools including the built-in RAG tool. The RAG tool specification must include a list of document collection IDs to retrieve from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd4664a-ff7f-4474-b6af-3a4ad3f73052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rag_agent = Agent(\n",
    "    client,\n",
    "    model=model_id,\n",
    "    instructions=\"You are a helpful assistant. Use the RAG tool available to you to answer user queries. When a tool is used, only print its output without adding more content.\",\n",
    "    sampling_params=sampling_params,\n",
    "    tools=[\n",
    "        dict(\n",
    "            name=\"builtin::rag/knowledge_search\",\n",
    "            args={\n",
    "                \"vector_db_ids\": [vector_db_id],\n",
    "            },\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3064b38-e9e1-46ca-9a7d-8a0c77a9c3a4",
   "metadata": {},
   "source": [
    "Now, our Llama Stack agent is ready to be served as an A2A agent. This includes the following steps:\n",
    " - Create an `AgentCard` - an object containing all the details about the agent we are about to serve, including its URL and exposed capabilities.\n",
    " - Wrap the Llama Stack agent with an `AgentTaskManager` object - a wrapper/adapter making it possible for the A2A server to redirect incoming request to the Llama Stack agent.\n",
    " - Create and launch an `A2AServer` - a Rest API server capable of communicating via the A2A protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f11c6a2-2568-4181-88e8-0e5eb514ed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [18664]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://localhost:10030 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     ::1:53138 - \"GET /.well-known/agent.json HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:53150 - \"POST / HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "rag_agent_local_port = int(os.getenv(\"RAG_AGENT_LOCAL_PORT\", \"10030\"))\n",
    "rag_agent_url = f\"http://localhost:{rag_agent_local_port}\"\n",
    "\n",
    "agent_card = AgentCard(\n",
    "    name=\"OpenShift Knowledge Source Agent\",\n",
    "    description=\"Provides information about all technical aspects related to Red Hat OpenShift\",\n",
    "    url=rag_agent_url,\n",
    "    version=\"0.1.0\",\n",
    "    defaultInputModes=[\"text/plain\"],\n",
    "    defaultOutputModes=[\"text/plain\"],\n",
    "    capabilities=AgentCapabilities(streaming=True),\n",
    "    skills=[\n",
    "        AgentSkill(id=\"rag\", name=\"RAG Query related to Red Hat OpenShift\"),\n",
    "    ],\n",
    ")\n",
    "task_manager = AgentTaskManager(agent=rag_agent)\n",
    "server = A2AServer(\n",
    "    agent_card=agent_card,\n",
    "    task_manager=task_manager,\n",
    "    host='localhost',\n",
    "    port=rag_agent_local_port\n",
    ")\n",
    "thread = threading.Thread(target=server.start, daemon=True)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5639413-90d6-42ae-add4-6c89da0297e2",
   "metadata": {},
   "source": [
    "## 3. Setting up an agent capable of A2A communication with the RAG agent\n",
    "This includes the following steps:\n",
    " - Create a Llama Stack client tool that wraps A2A communication with the RAG agent.\n",
    " - Initialize a client agent with access to the above client tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7414837e-b04e-432d-82c3-6719a8f62132",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_agent_tool = A2ATool(rag_agent_url)\n",
    "a2a_client_agent = Agent(\n",
    "    client,\n",
    "    model=model_id,\n",
    "    instructions=\"You are a helpful assistant. When a tool is used, only print its output without adding more content.\",\n",
    "    sampling_params=sampling_params,\n",
    "    tools=[rag_agent_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d24b33-72cd-47b0-b5e4-14cdd954ef18",
   "metadata": {},
   "source": [
    "Now, let's use our client agent for serving user requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b9baa2-4739-426a-b79a-2ff90f44c023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "User> How to install OpenShift?\u001b[0m\n",
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: OpenShift Knowledge Source Agent, Arguments: {'query': 'installing OpenShift'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'{\"type\": \"function\", \"name\": \"knowledge_search\", \"parameters\": {\"query\": \"OpenShift installation\"}}Tool:knowledge_search Args:{\\'query\\': \\'OpenShift installation\\'}Tool:knowledge_search Response:[TextContentItem(text=\\'knowledge_search tool found 5 chunks:\\\\nBEGIN of knowledge_search tool results.\\\\n\\', type=\\'text\\'), TextContentItem(text=\\'Result 1:\\\\nDocument_id:num-0\\\\nContent:  We\\\\nrecommend you to check the official Red Hat OpenShift Local documentation for an updated list of\\\\nrequirements at the official documentation website.\\\\n\\\\uf05a\\\\nRegarding Linux, even if Red Hat does not officially support them, OpenShift Local\\\\ncan run on other distributions, such as Ubuntu or Debian, with minor caveats.\\\\nRunning OpenShift Local on any Linux distribution requires a few additional\\\\nsoftware packages to be installed through your default package manager. The\\\\n15\\\\ndocumentation at crc.dev/crc has more information about this subject.\\\\n7.2. Hardware Requirements\\\\nIn terms of hardware, OpenShift Local has some strict requirements. Your system must use a recent\\\\nIntel CPU (except for Macs, where Apple Silicon machines are supported) with at least four physical\\\\ncores and have at least 16 GB of RAM. Be aware that the base installation of OpenShift Local\\\\nrequires at least 9 GB free to start. Of course, to run other applications on OpenShift Local, you will\\\\nneed more RAM, so using a computer with at least 32 GB of RAM is strongly recommended.\\\\nOpenShift Local also requires at least 35 GB of free disk space for its installation. The memory\\\\nrequirements are likely to increase in the future, so please check the documentation at crc.dev for\\\\nmore up-to-date information.\\\\n7.3. Installation\\\\nTo install OpenShift Local, open your web browser and navigate to console.redhat.com/openshift/\\\\ncreate/local . Download the latest release of OpenShift Local and the \"pull secret\" file. The latter is a\\\\nfile containing a key identifying your copy of OpenShift Local to your Red Hat Developer account.\\\\nUnzip the file containing the OpenShift Local executable, and using your terminal, run the\\\\ncommand crc setup . This command will prepare your copy of OpenShift Local, verifying\\\\nrequirements and setting the required configuration values.\\\\nOnce the crc setup command is ready, launch crc start. Running crc start can take a long time,\\\\naround 20 minutes, on a recent PC.\\\\nOnce started, access the OpenShift Web Console with the crc console command, which will open\\\\nyour default browser. OpenShift Local uses the developer username and password to log in as a\\\\nlow-privilege user, while the kubeadmin user uses a random-generated password. Use the crc\\\\nconsole --credentials command to find the credentials required to log in as the kubeadmin user.\\\\nOpenShift Local allows developers to perform various everyday tasks as if it were a standard\\\\nOpenShift cluster, like deploying applications\\\\n\\', type=\\'text\\'), TextContentItem(text=\\'Result 2:\\\\nDocument_id:num-0\\\\nContent: .\\\\nThese characteristics set OpenShift apart as an excellent Kubernetes platform for enterprise users.\\\\nThe latest version of OpenShift available at the time of this writing is 4.12.\\\\n3.2. Is Red Hat OpenShift Open Source?\\\\nRed Hat OpenShift is a commercial product based on an open-source project called OKD. This\\\\nacronym means \" OpenShift Kubernetes Distribution\" and is publicly available for everyone to\\\\ninspect and contribute. Like the upstream Kubernetes project, OKD developers use the Go\\\\nprogramming language.\\\\n3.3. How can I run OpenShift?\\\\nToday, Red Hat OpenShift is available through various mechanisms and formats:\\\\n• DevOps teams can install it in their data centers \"on-premise.\"\\\\n• Major hyperscalers such as AWS, Azure, Google Cloud Platform, and IBM Cloud offer managed\\\\nRed Hat OpenShift installations.\\\\n• Developers can either run OpenShift locally on their workstations using Red Hat OpenShift\\\\nLocal, also known as CRC or \"Code-Ready Containers\"\\\\n• They can also request a 30-day trial OpenShift cluster, offered by Red Hat, at no charge, for\\\\ntesting and evaluation purposes.\\\\nRed Hat OpenShift is an integrated Platform-as-a-Service for enterprise users based on Kubernetes.\\\\nIt is tightly integrated with advanced security settings, developer tooling, and monitoring\\\\nmechanisms, allowing DevOps teams to be more productive.\\\\n8\\\\nChapter 4. OpenShift-only Custom Resource\\\\nDefinitions\\\\nRed Hat OpenShift is a complete DevOps platform extending Kubernetes in various ways. It bundles\\\\na constellation of Custom Resource Definitions (CRDs) to make the life of developers and cluster\\\\nadministrators easier.\\\\nLet us talk first about the CRDs only available on OpenShift.\\\\n4.1. Project\\\\nAn OpenShift Project is similar to a Kubernetes namespace, but more tightly integrated into the\\\\nsecurity system of OpenShift through additional annotations.\\\\napiVersion: project.openshift.io/v1\\\\nkind: Project\\\\nmetadata:\\\\n\\\\xa0 name: linkedin-learning-project\\\\n\\\\xa0 annotations:\\\\n\\\\xa0   openshift.io/description: \"Project description\"\\\\n\\\\xa0   openshift.io/display-name: \"Display name\"\\\\n4.2. Route\\\\nThe OpenShift Route object was one of the primary inspirations during the development of the\\\\nIngress object. In OpenShift, Ingress and Route objects work together to ensure your applications\\\\nare available outside the cluster.\\\\napiVersion: route.openshift.io/v1\\\\nkind: Route\\\\nmetadata:\\\\n\\\\xa0 name: my-route\\\\nspec:\\\\n\\\\xa0 host:\\\\n\\', type=\\'text\\'), TextContentItem(text=\\'Result 3:\\\\nDocument_id:num-0\\\\nContent:  \"Import from Git\" entry. Click on it, and paste the URL of a project, for example,\\\\ngitlab.com/akosma/simple-deno-api.git.\\\\nAs soon as you paste the URL, OpenShift will immediately analyze the structure and programming\\\\nlanguage of the project and automatically recommend options for its build process. In our case, it’s\\\\na small application built with the Go programming language, and as such, it will advise the options\\\\nshown on the screen.\\\\nFigure 5. Deploying a project directly from its Git repository\\\\n25\\\\nThis particular example doesn’t require more configurations than the ones shown on the screen;\\\\nclick the [\\\\u2009Create\\\\u2009] button.\\\\nAfter a few seconds, you will see your application running on the \"Topology\" screen. OpenShift will\\\\ndownload the source code and trigger your project’s build. Click on the Topology screen icon to see\\\\nthe \"Build\" section, indicating that a build is running. The compilation and deployment of your\\\\napplication can take some time, depending on the complexity of the source code and the\\\\nprogramming language used.\\\\nOnce the build has finished, on the same pane, you will see a route available under the \"Routes\"\\\\nsection. Click on it, and you will see your application in action.\\\\n10.2. Container Registry\\\\nOpenShift has built your application source code, and the product of this build process is a\\\\ncontainer. You can see the container that OpenShift made for you on the \"Administrator\"\\\\nperspective, selecting the \"Builds\" menu and then the \"ImageStreams\" menu entry.\\\\nOpenShift includes a container registry; developers can use it as any other registry from outside the\\\\ncluster. Let us use \"podman\" to access the container registry and run the container locally on your\\\\nworkstation.\\\\nUsers must have the \"registry-editor\" and the \"system:image-builder\" roles to access the container\\\\nregistry. Since we’re connected to the Web Console using the \"kubeadmin\" user, we can provide\\\\nthose roles directly from the user interface without using the command line.\\\\nNavigate to the \"User Management\" section and select \"RoleBindings.\" Click on the [\\\\u2009Create\\\\nbinding\\\\u2009] button, and fill the form using the following values:\\\\n• Name: developer-sourcecode-registry-editor\\\\n• Namespace: sourcecode\\\\n• Role name: registry-editor\\\\n• Subject: User\\\\n• Subject name: developer\\\\nDo the same for the \"system:image-builder\" role, using a different \"Name\" field\\\\n\\', type=\\'text\\'), TextContentItem(text=\\'Result 4:\\\\nDocument_id:num-0\\\\nContent:  Git repository, for example, but not\\\\n22\\\\nlimited to GitHub, GitLab, Gitea, or other locations.\\\\n• Importing YAML directly or even a JAR file with a Java application.\\\\nLet us select the \"Container Image\" option, where we can specify the URL of a ready-to-use\\\\ncontainer.\\\\nEnter the URL of the container on the field, and click on the [\\\\u2009Create\\\\u2009] button at the bottom of the\\\\npage. You do not need to change any other value on the form.\\\\nA few seconds later, depending on the size of the container and the speed of your Internet\\\\nconnection, OpenShift will have pulled the container and deployed it onto your cluster. This\\\\ndeployment will include the usual standard elements: a \"Deployment\" object, a \"Service\" object, and\\\\na \"Route.\"\\\\nOpenShift offers a visual representation of the applications running on your project: click on the\\\\nicon of your container, and you will see a panel opening on the right side of the screen. This panel\\\\nwill include the URL automatically assigned to your deployment, and clicking it will show the\\\\napplication in action in another browser tab.\\\\nFigure 4. Topology screen on Red Hat OpenShift\\\\n9.2. Creating and Debugging Applications with the odo\\\\nTool\\\\nWith the oc tool, Red Hat provides another one geared toward software developers: the odo tool.\\\\nDevelopers can use the odo tool to create applications using \"Devfiles,\" particular files named\\\\n\"devfile.yaml\" based on an open standard available at the Devfiles website. Devfiles contain\\\\ninformation about your application’s programming language, dependencies, and other essential\\\\ndetails.\\\\n23\\\\nThe odo tool is not available by default on your command line, but you can download it from the\\\\n\"Help\" menu on the OpenShift Web Console through the \"Command line tools\" entry. Click on the\\\\n\"Download odo\" link at the bottom, and select the version of odo that corresponds to your system.\\\\nThe \"odo catalog list components was\" command shows the various programming languages and\\\\nframeworks supported off-the-box by \"odo.\"\\\\nThe odo init  command prompts the user for a new application using many programming\\\\nlanguages: .NET, Go, Java, JavaScript, PHP, Python, and TypeScript. The last command generates a\\\\nscaffold ready to be populated with the required logic. Finally, the odo push command builds and\\\\npushes the container to the OpenShift container registry, deploying\\\\n\\', type=\\'text\\'), TextContentItem(text=\\'Result 5:\\\\nDocument_id:num-0\\\\nContent: _02 branch of the GitHub\\\\nrepository for this course.\\\\nThe whole point of OpenShift is to be able to deploy, run, and monitor containerized applications.\\\\nDevOps engineers can deploy containers in OpenShift clusters through various means, for example:\\\\n• Using a YAML manifest.\\\\n• Deploying a single container using the web console.\\\\n• Building a project stored in a Git repository anywhere on the Internet and deploying the\\\\nresulting container.\\\\n• Using the integrated CI/CD pipelines.\\\\n• Using the odo tool together with \"Devfiles.\"\\\\nEach approach has pros and cons; in this chapter, we will review how to use the web console and\\\\nhow to use the odo tool.\\\\n9.1. Deploying Applications with the Web Console\\\\nDevOps engineers can deploy applications immediately using the Web Console. Launch your CRC\\\\ninstance and open the web console in your preferred web browser. The URL of the OpenShift web\\\\nconsole is \"https://console-openshift-console.apps-crc.testing.\"\\\\nThe OpenShift Web Console offers two major perspectives:\\\\n• The \"Administrator\" perspective.\\\\n• And the \"Developer\" perspective.\\\\nFor this explanation, select the \"Developer\" perspective.\\\\nThe first time you open the Developer perspective, a popup invites you to follow a user interface\\\\ntour.\\\\nOn the left-hand side, the perspective menu shows an entry titled \"Add,\" which, as the name\\\\nimplies, provides various mechanisms to deploy applications on an OpenShift cluster.\\\\nThe \"Add\" screen shows the various ways DevOps engineers can deploy applications on a cluster:\\\\n• Using the Developer Catalog, browsing and choosing among a long list of available databases,\\\\nmessage queues, and other valuable components to build applications, or entering your\\\\npreferred Helm chart repository to extend the catalog.\\\\n• Specifying the URL to a specific container on any standard container registry.\\\\n• Specifying the URL of a source code project stored on a Git repository, for example, but not\\\\n22\\\\nlimited to GitHub, GitLab, Gitea, or other locations.\\\\n• Importing YAML directly or even a JAR file with a Java application.\\\\nLet us select the \"Container Image\" option, where we can specify the URL of a ready-to-use\\\\ncontainer.\\\\nEnter the URL of the container on the field, and click on the [\\\\u2009Create\\\\u2009] button at the bottom of the\\\\npage. You do not need to change any other value on the form.\\\\nA few seconds later, depending on the size of the container and the speed of your Internet\\\\nconnection,\\\\n\\', type=\\'text\\'), TextContentItem(text=\\'END of knowledge_search tool results.\\\\n\\', type=\\'text\\')]To install OpenShift, you can follow these steps:\\n\\n1. Check the official Red Hat OpenShift Local documentation for an updated list of requirements at the official documentation website.\\n2. Ensure your system meets the hardware requirements: a recent Intel CPU (except for Macs, where Apple Silicon machines are supported) with at least four physical cores and 16 GB of RAM.\\n3. Download the latest release of OpenShift Local and the \"pull secret\" file from console.redhat.com/openshift/create/local.\\n4. Unzip the file containing the OpenShift Local executable and run the command `crc setup` to prepare your copy of OpenShift Local, verifying requirements and setting the required configuration values.\\n5. Launch crc start, which can take around 20 minutes on a recent PC.\\n6. Access the OpenShift Web Console with the crc console command, which will open your default browser. Log in as a low-privilege user using the developer username and password, while the kubeadmin user uses a random-generated password. Use the crc console --credentials command to find the credentials required to log in as the kubeadmin user.\\n\\nAlternatively, you can also install OpenShift using the odo tool by downloading it from the \"Help\" menu on the OpenShift Web Console through the \"Command line tools\" entry and following the prompts to create a new application using Devfiles.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"type\": \"function\", \"name\": \"knowledge_search\", \"parameters\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"query\": \"OpenShift installation\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32mTool:knowledge_search Args:\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'query\\': \\'OpenShift installation\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32mTool:knowledge_search Response:\u001b[0m\u001b[32m[\u001b[0m\u001b[32mTextContentItem\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m=\\'knowledge_search tool found 5 chunks:\\\\nBEGIN of knowledge_search tool results.\\\\n\\', \u001b[0m\u001b[32mtype\u001b[0m\u001b[32m=\\'text\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, TextContentItem\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m=\\'Result 1:\\\\nDocument_id:num-0\\\\nContent:  We\\\\nrecommend you to check the official Red Hat OpenShift Local documentation for an updated list of\\\\nrequirements at the official documentation website.\\\\n\\\\uf05a\\\\nRegarding Linux, even if Red Hat does not officially support them, OpenShift Local\\\\ncan run on other distributions, such as Ubuntu or Debian, with minor caveats.\\\\nRunning OpenShift Local on any Linux distribution requires a few additional\\\\nsoftware packages to be installed through your default package manager. The\\\\n15\\\\ndocumentation at crc.dev/crc has more information about this subject.\\\\n7.2. Hardware Requirements\\\\nIn terms of hardware, OpenShift Local has some strict requirements. Your system must use a recent\\\\nIntel CPU \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexcept for Macs, where Apple Silicon machines are supported\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with at least four physical\\\\ncores and have at least 16 GB of RAM. Be aware that the base installation of OpenShift Local\\\\nrequires at least 9 GB free to start. Of course, to run other applications on OpenShift Local, you will\\\\nneed more RAM, so using a computer with at least 32 GB of RAM is strongly recommended.\\\\nOpenShift Local also requires at least 35 GB of free disk space for its installation. The memory\\\\nrequirements are likely to increase in the future, so please check the documentation at crc.dev for\\\\nmore up-to-date information.\\\\n7.3. Installation\\\\nTo install OpenShift Local, open your web browser and navigate to console.redhat.com/openshift/\\\\ncreate/local . Download the latest release of OpenShift Local and the \"pull secret\" file. The latter is a\\\\nfile containing a key identifying your copy of OpenShift Local to your Red Hat Developer account.\\\\nUnzip the file containing the OpenShift Local executable, and using your terminal, run the\\\\ncommand crc setup . This command will prepare your copy of OpenShift Local, verifying\\\\nrequirements and setting the required configuration values.\\\\nOnce the crc setup command is ready, launch crc start. Running crc start can take a long time,\\\\naround 20 minutes, on a recent PC.\\\\nOnce started, access the OpenShift Web Console with the crc console command, which will open\\\\nyour default browser. OpenShift Local uses the developer username and password to log in as a\\\\nlow-privilege user, while the kubeadmin user uses a random-generated password. Use the crc\\\\nconsole --credentials command to find the credentials required to log in as the kubeadmin user.\\\\nOpenShift Local allows developers to perform various everyday tasks as if it were a standard\\\\nOpenShift cluster, like deploying applications\\\\n\\', \u001b[0m\u001b[32mtype\u001b[0m\u001b[32m=\\'text\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, TextContentItem\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m=\\'Result 2:\\\\nDocument_id:num-0\\\\nContent: .\\\\nThese characteristics set OpenShift apart as an excellent Kubernetes platform for enterprise users.\\\\nThe latest version of OpenShift available at the time of this writing is 4.12.\\\\n3.2. Is Red Hat OpenShift Open Source?\\\\nRed Hat OpenShift is a commercial product based on an open-source project called OKD. This\\\\nacronym means \" OpenShift Kubernetes Distribution\" and is publicly available for everyone to\\\\ninspect and contribute. Like the upstream Kubernetes project, OKD developers use the Go\\\\nprogramming language.\\\\n3.3. How can I run OpenShift?\\\\nToday, Red Hat OpenShift is available through various mechanisms and formats:\\\\n• DevOps teams can install it in their data centers \"on-premise.\"\\\\n• Major hyperscalers such as AWS, Azure, Google Cloud Platform, and IBM Cloud offer managed\\\\nRed Hat OpenShift installations.\\\\n• Developers can either run OpenShift locally on their workstations using Red Hat OpenShift\\\\nLocal, also known as CRC or \"Code-Ready Containers\"\\\\n• They can also request a 30-day trial OpenShift cluster, offered by Red Hat, at no charge, for\\\\ntesting and evaluation purposes.\\\\nRed Hat OpenShift is an integrated Platform-as-a-Service for enterprise users based on Kubernetes.\\\\nIt is tightly integrated with advanced security settings, developer tooling, and monitoring\\\\nmechanisms, allowing DevOps teams to be more productive.\\\\n8\\\\nChapter 4. OpenShift-only Custom Resource\\\\nDefinitions\\\\nRed Hat OpenShift is a complete DevOps platform extending Kubernetes in various ways. It bundles\\\\na constellation of Custom Resource Definitions \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCRDs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to make the life of developers and cluster\\\\nadministrators easier.\\\\nLet us talk first about the CRDs only available on OpenShift.\\\\n4.1. Project\\\\nAn OpenShift Project is similar to a Kubernetes namespace, but more tightly integrated into the\\\\nsecurity system of OpenShift through additional annotations.\\\\napiVersion: project.openshift.io/v1\\\\nkind: Project\\\\nmetadata:\\\\n\\\\xa0 name: linkedin-learning-project\\\\n\\\\xa0 annotations:\\\\n\\\\xa0   openshift.io/description: \"Project description\"\\\\n\\\\xa0   openshift.io/display-name: \"Display name\"\\\\n4.2. Route\\\\nThe OpenShift Route object was one of the primary inspirations during the development of the\\\\nIngress object. In OpenShift, Ingress and Route objects work together to ensure your applications\\\\nare available outside the cluster.\\\\napiVersion: route.openshift.io/v1\\\\nkind: Route\\\\nmetadata:\\\\n\\\\xa0 name: my-route\\\\nspec:\\\\n\\\\xa0 host:\\\\n\\', \u001b[0m\u001b[32mtype\u001b[0m\u001b[32m=\\'text\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, TextContentItem\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m=\\'Result 3:\\\\nDocument_id:num-0\\\\nContent:  \"Import from Git\" entry. Click on it, and paste the URL of a project, for example,\\\\ngitlab.com/akosma/simple-deno-api.git.\\\\nAs soon as you paste the URL, OpenShift will immediately analyze the structure and programming\\\\nlanguage of the project and automatically recommend options for its build process. In our case, it’s\\\\na small application built with the Go programming language, and as such, it will advise the options\\\\nshown on the screen.\\\\nFigure 5. Deploying a project directly from its Git repository\\\\n25\\\\nThis particular example doesn’t require more configurations than the ones shown on the screen;\\\\nclick the \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\u2009Create\\\\u2009\u001b[0m\u001b[32m]\u001b[0m\u001b[32m button.\\\\nAfter a few seconds, you will see your application running on the \"Topology\" screen. OpenShift will\\\\ndownload the source code and trigger your project’s build. Click on the Topology screen icon to see\\\\nthe \"Build\" section, indicating that a build is running. The compilation and deployment of your\\\\napplication can take some time, depending on the complexity of the source code and the\\\\nprogramming language used.\\\\nOnce the build has finished, on the same pane, you will see a route available under the \"Routes\"\\\\nsection. Click on it, and you will see your application in action.\\\\n10.2. Container Registry\\\\nOpenShift has built your application source code, and the product of this build process is a\\\\ncontainer. You can see the container that OpenShift made for you on the \"Administrator\"\\\\nperspective, selecting the \"Builds\" menu and then the \"ImageStreams\" menu entry.\\\\nOpenShift includes a container registry; developers can use it as any other registry from outside the\\\\ncluster. Let us use \"podman\" to access the container registry and run the container locally on your\\\\nworkstation.\\\\nUsers must have the \"registry-editor\" and the \"system:image-builder\" roles to access the container\\\\nregistry. Since we’re connected to the Web Console using the \"kubeadmin\" user, we can provide\\\\nthose roles directly from the user interface without using the command line.\\\\nNavigate to the \"User Management\" section and select \"RoleBindings.\" Click on the \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\u2009Create\\\\nbinding\\\\u2009\u001b[0m\u001b[32m]\u001b[0m\u001b[32m button, and fill the form using the following values:\\\\n• Name: developer-sourcecode-registry-editor\\\\n• Namespace: sourcecode\\\\n• Role name: registry-editor\\\\n• Subject: User\\\\n• Subject name: developer\\\\nDo the same for the \"system:image-builder\" role, using a different \"Name\" field\\\\n\\', \u001b[0m\u001b[32mtype\u001b[0m\u001b[32m=\\'text\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, TextContentItem\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m=\\'Result 4:\\\\nDocument_id:num-0\\\\nContent:  Git repository, for example, but not\\\\n22\\\\nlimited to GitHub, GitLab, Gitea, or other locations.\\\\n• Importing YAML directly or even a JAR file with a Java application.\\\\nLet us select the \"Container Image\" option, where we can specify the URL of a ready-to-use\\\\ncontainer.\\\\nEnter the URL of the container on the field, and click on the \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\u2009Create\\\\u2009\u001b[0m\u001b[32m]\u001b[0m\u001b[32m button at the bottom of the\\\\npage. You do not need to change any other value on the form.\\\\nA few seconds later, depending on the size of the container and the speed of your Internet\\\\nconnection, OpenShift will have pulled the container and deployed it onto your cluster. This\\\\ndeployment will include the usual standard elements: a \"Deployment\" object, a \"Service\" object, and\\\\na \"Route.\"\\\\nOpenShift offers a visual representation of the applications running on your project: click on the\\\\nicon of your container, and you will see a panel opening on the right side of the screen. This panel\\\\nwill include the URL automatically assigned to your deployment, and clicking it will show the\\\\napplication in action in another browser tab.\\\\nFigure 4. Topology screen on Red Hat OpenShift\\\\n9.2. Creating and Debugging Applications with the odo\\\\nTool\\\\nWith the oc tool, Red Hat provides another one geared toward software developers: the odo tool.\\\\nDevelopers can use the odo tool to create applications using \"Devfiles,\" particular files named\\\\n\"devfile.yaml\" based on an open standard available at the Devfiles website. Devfiles contain\\\\ninformation about your application’s programming language, dependencies, and other essential\\\\ndetails.\\\\n23\\\\nThe odo tool is not available by default on your command line, but you can download it from the\\\\n\"Help\" menu on the OpenShift Web Console through the \"Command line tools\" entry. Click on the\\\\n\"Download odo\" link at the bottom, and select the version of odo that corresponds to your system.\\\\nThe \"odo catalog list components was\" command shows the various programming languages and\\\\nframeworks supported off-the-box by \"odo.\"\\\\nThe odo init  command prompts the user for a new application using many programming\\\\nlanguages: .NET, Go, Java, JavaScript, PHP, Python, and TypeScript. The last command generates a\\\\nscaffold ready to be populated with the required logic. Finally, the odo push command builds and\\\\npushes the container to the OpenShift container registry, deploying\\\\n\\', \u001b[0m\u001b[32mtype\u001b[0m\u001b[32m=\\'text\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, TextContentItem\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m=\\'Result 5:\\\\nDocument_id:num-0\\\\nContent: _02 branch of the GitHub\\\\nrepository for this course.\\\\nThe whole point of OpenShift is to be able to deploy, run, and monitor containerized applications.\\\\nDevOps engineers can deploy containers in OpenShift clusters through various means, for example:\\\\n• Using a YAML manifest.\\\\n• Deploying a single container using the web console.\\\\n• Building a project stored in a Git repository anywhere on the Internet and deploying the\\\\nresulting container.\\\\n• Using the integrated CI/CD pipelines.\\\\n• Using the odo tool together with \"Devfiles.\"\\\\nEach approach has pros and cons; in this chapter, we will review how to use the web console and\\\\nhow to use the odo tool.\\\\n9.1. Deploying Applications with the Web Console\\\\nDevOps engineers can deploy applications immediately using the Web Console. Launch your CRC\\\\ninstance and open the web console in your preferred web browser. The URL of the OpenShift web\\\\nconsole is \"https://console-openshift-console.apps-crc.testing.\"\\\\nThe OpenShift Web Console offers two major perspectives:\\\\n• The \"Administrator\" perspective.\\\\n• And the \"Developer\" perspective.\\\\nFor this explanation, select the \"Developer\" perspective.\\\\nThe first time you open the Developer perspective, a popup invites you to follow a user interface\\\\ntour.\\\\nOn the left-hand side, the perspective menu shows an entry titled \"Add,\" which, as the name\\\\nimplies, provides various mechanisms to deploy applications on an OpenShift cluster.\\\\nThe \"Add\" screen shows the various ways DevOps engineers can deploy applications on a cluster:\\\\n• Using the Developer Catalog, browsing and choosing among a long list of available databases,\\\\nmessage queues, and other valuable components to build applications, or entering your\\\\npreferred Helm chart repository to extend the catalog.\\\\n• Specifying the URL to a specific container on any standard container registry.\\\\n• Specifying the URL of a source code project stored on a Git repository, for example, but not\\\\n22\\\\nlimited to GitHub, GitLab, Gitea, or other locations.\\\\n• Importing YAML directly or even a JAR file with a Java application.\\\\nLet us select the \"Container Image\" option, where we can specify the URL of a ready-to-use\\\\ncontainer.\\\\nEnter the URL of the container on the field, and click on the \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\u2009Create\\\\u2009\u001b[0m\u001b[32m]\u001b[0m\u001b[32m button at the bottom of the\\\\npage. You do not need to change any other value on the form.\\\\nA few seconds later, depending on the size of the container and the speed of your Internet\\\\nconnection,\\\\n\\', \u001b[0m\u001b[32mtype\u001b[0m\u001b[32m=\\'text\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, TextContentItem\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m=\\'END of knowledge_search tool results.\\\\n\\', \u001b[0m\u001b[32mtype\u001b[0m\u001b[32m=\\'text\\'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m]\u001b[0m\u001b[32mTo install OpenShift, you can follow these steps:\\n\\n1. Check the official Red Hat OpenShift Local documentation for an updated list of requirements at the official documentation website.\\n2. Ensure your system meets the hardware requirements: a recent Intel CPU \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexcept for Macs, where Apple Silicon machines are supported\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with at least four physical cores and 16 GB of RAM.\\n3. Download the latest release of OpenShift Local and the \"pull secret\" file from console.redhat.com/openshift/create/local.\\n4. Unzip the file containing the OpenShift Local executable and run the command `crc setup` to prepare your copy of OpenShift Local, verifying requirements and setting the required configuration values.\\n5. Launch crc start, which can take around 20 minutes on a recent PC.\\n6. Access the OpenShift Web Console with the crc console command, which will open your default browser. Log in as a low-privilege user using the developer username and password, while the kubeadmin user uses a random-generated password. Use the crc console --credentials command to find the credentials required to log in as the kubeadmin user.\\n\\nAlternatively, you can also install OpenShift using the odo tool by downloading it from the \"Help\" menu on the OpenShift Web Console through the \"Command line tools\" entry and following the prompts to create a new application using Devfiles.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35mTo install OpenShift, follow these steps:\n",
      "\n",
      "1. Check the official Red Hat OpenShift Local documentation for an updated list of requirements at the official documentation website.\n",
      "2. Ensure your system meets the hardware requirements: a recent Intel CPU (except for Macs, where Apple Silicon machines are supported) with at least four physical cores and 16 GB of RAM.\n",
      "3. Download the latest release of OpenShift Local and the \"pull secret\" file from console.redhat.com/openshift/create/local.\n",
      "4. Unzip the file containing the OpenShift Local executable and run the command `crc setup` to prepare your copy of OpenShift Local, verifying requirements and setting the required configuration values.\n",
      "5. Launch crc start, which can take around 20 minutes on a recent PC.\n",
      "6. Access the OpenShift Web Console with the crc console command, which will open your default browser. Log in as a low-privilege user using the developer username and password, while the kubeadmin user uses a random-generated password. Use the crc console --credentials command to find the credentials required to log in as the kubeadmin user.\n",
      "\n",
      "Alternatively, you can also install OpenShift using the odo tool by downloading it from the \"Help\" menu on the OpenShift Web Console through the \"Command line tools\" entry and following the prompts to create a new application using Devfiles.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"How to install OpenShift?\",\n",
    "]\n",
    "\n",
    "for prompt in queries:\n",
    "    cprint(f\"\\nUser> {prompt}\", \"blue\")\n",
    "    \n",
    "    # create a new turn with a new session ID for each prompt\n",
    "    response = a2a_client_agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        session_id=a2a_client_agent.create_session(f\"rag-session_{uuid.uuid4()}\"),\n",
    "        stream=stream,\n",
    "    )\n",
    "    \n",
    "    # print the response, including tool calls output\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6937a3-3efa-4b66-aaf0-85d96b6d43db",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "This notebook demonstrated how to use the basic A2A functionality with Llama Stack. We did this by creating an agent, making it available it over an A2A server, and using another agent to collaborate with it for serving a user request.\n",
    "\n",
    "Future demos will cover more advanced aspects of agent-to-agent communication."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
